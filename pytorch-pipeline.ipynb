{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d0ab47-8092-4585-88ad-e0a1c9f0f080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importer to get the task.py file to the second component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57fe685-3a65-4719-b98b-3ff4ea639d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b9f2b9-e2c5-4260-971c-e33410d537bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip3 install google-cloud-aiplatform==1.0.0 --upgrade\n",
    "!pip3 install kfp google-cloud-pipeline-components==0.1.1 --upgrade\n",
    "!pip3 install scikit-learn\n",
    "!pip3 install google-cloud-aiplatform --upgrade\n",
    "!pip3 install pandas\n",
    "!pip3 install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b6554e9-3fde-4316-b3b3-c562aa489f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from kfp import dsl\n",
    "import kfp\n",
    "from google.cloud import aiplatform\n",
    "from kfp.v2.dsl import component\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output, OutputPath, component, ClassificationMetrics, Metrics)\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c5d1d6c-a96a-4bf5-b6ff-339c81e19463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kubeflow-demos\n",
      "user-group-demo\n",
      "gs://user-group-demo/pipeline_root\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/a/54028874\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "PROJECT_ID = os.environ['PROJECT_ID']\n",
    "BUCKET_NAME = os.environ['BUCKET']\n",
    "\n",
    "PIPELINE_ROOT = 'gs://{}/pipeline_root'.format(BUCKET_NAME)\n",
    "REGION = 'us-central1'\n",
    "\n",
    "print(PROJECT_ID)\n",
    "print(BUCKET_NAME)\n",
    "print(PIPELINE_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5bcda57-2b49-4b27-a758-54385d147b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test-pkl/task.py\n",
    "@component(packages_to_install=[\"google-cloud-storage\"])\n",
    "def download_file(bucket_name: str, source_blob_name: str, output_file_path: OutputPath()):\n",
    "\n",
    "    from google.cloud import storage\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    \n",
    "    blob = bucket.blob(source_blob_name)\n",
    "    blob.download_to_filename(output_file_path)\n",
    "\n",
    "    print(\n",
    "        \"Downloaded storage object {} from bucket {} to local file {}.\".format(\n",
    "            source_blob_name, bucket_name, output_file_path\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e391d30d-05bd-4d72-9a55-7455b4cf9692",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(packages_to_install=[\"pandas\", \"google-cloud-aiplatform\", \"google-cloud-storage\", \"pillow\", \"numpy\"])\n",
    "def train(input_file_path: InputPath()):\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    from google.cloud import aiplatform\n",
    "    from google.cloud.aiplatform import gapic as aip\n",
    "\n",
    "    PROJECT_ID = \"kubeflow-demos\"\n",
    "    BUCKET_NAME = \"gs://test-pkl\"  # @param {type:\"string\"}\n",
    "    REGION = \"us-central1\"\n",
    "\n",
    "    aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_NAME)\n",
    "\n",
    "    TRAIN_GPU, TRAIN_NGPU = (aip.AcceleratorType.NVIDIA_TESLA_V100, 2)\n",
    "    TRAIN_VERSION = \"pytorch-gpu.1-7\"\n",
    "    TRAIN_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/{}:latest\".format(TRAIN_VERSION)\n",
    "\n",
    "    print(\"Training:\", TRAIN_IMAGE, TRAIN_GPU, TRAIN_NGPU)\n",
    "\n",
    "    MACHINE_TYPE = \"n1-standard\"\n",
    "\n",
    "    VCPU = \"16\"\n",
    "    TRAIN_COMPUTE = MACHINE_TYPE + \"-\" + VCPU\n",
    "    print(\"Train machine type\", TRAIN_COMPUTE)\n",
    "\n",
    "    TRAIN_NCOMPUTE_MASTER = 1\n",
    "    TRAIN_NCOMPUTE_WORKER = 2\n",
    "\n",
    "\n",
    "    from datetime import datetime\n",
    "\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    print (TIMESTAMP)\n",
    "\n",
    "    JOB_NAME = \"cifar10_resnet_custom_job_\" + TIMESTAMP\n",
    "\n",
    "    ARGS = [\n",
    "        \"--dist-url=\" + \"env://\",\n",
    "        \"--multiprocessing-distributed\",\n",
    "        \"--num_epochs=2\"\n",
    "    ]\n",
    "\n",
    "    base_output_dir = '{}/jobs/{}'.format(BUCKET_NAME, JOB_NAME)\n",
    "\n",
    "    job = aiplatform.CustomTrainingJob(\n",
    "        display_name=JOB_NAME,\n",
    "        script_path=input_file_path,\n",
    "        container_uri=TRAIN_IMAGE,\n",
    "        staging_bucket=base_output_dir,\n",
    "    #    requirements=[\"tensorflow_datasets==1.3.0\"],\n",
    "    #    model_serving_container_image_uri=DEPLOY_IMAGE,\n",
    "    )\n",
    "\n",
    "    MODEL_DISPLAY_NAME = \"cifar10-pytorch-\" + TIMESTAMP\n",
    "    print(MODEL_DISPLAY_NAME)\n",
    "    \n",
    "    # Start the training\n",
    "    if TRAIN_GPU:\n",
    "        model = job.run(\n",
    "            #model_display_name=MODEL_DISPLAY_NAME,\n",
    "            args=ARGS,\n",
    "            replica_count=TRAIN_NCOMPUTE_WORKER + TRAIN_NCOMPUTE_MASTER,\n",
    "            machine_type=TRAIN_COMPUTE,\n",
    "            accelerator_type=TRAIN_GPU.name,\n",
    "            accelerator_count=TRAIN_NGPU,\n",
    "        )\n",
    "    else:\n",
    "        model = job.run(\n",
    "            model_display_name=MODEL_DISPLAY_NAME,\n",
    "            args=ARGS,\n",
    "            replica_count=1,\n",
    "            machine_type=TRAIN_COMPUTE,\n",
    "            accelerator_count=0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d77ed01-5fd1-4ff2-a931-9c5eebf338e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "868e19bd-4318-43e3-8d83-3f0f9d3582a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name=\"download-file\" + str(uuid.uuid4()))\n",
    "def pipeline(baseline_accuracy: float = 70.0):\n",
    "    download_file_task = download_file('test-pkl','task.py')\n",
    "    train_task = train(download_file_task.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8eca348d-837e-4a44-8a74-8596305a1d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler\n",
    "\n",
    "compiler.Compiler().compile(pipeline_func=pipeline, \n",
    "                            package_path=\"dag-\"+TIMESTAMP+\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21d0e27b-ccf3-462f-bba7-0ea39a74639e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yarkoni/projects/managed-pipelines-pytorch/venv/lib/python3.9/site-packages/kfp/v2/google/client/client.py:171: FutureWarning: AIPlatformClient will be deprecated in v1.9. Please use PipelineJob https://googleapis.dev/python/aiplatform/latest/_modules/google/cloud/aiplatform/pipeline_jobs.html in Vertex SDK. Install the SDK using \"pip install google-cloud-aiplatform\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "api_client = AIPlatformClient(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=REGION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e050889-35d5-4ed4-b7eb-bec0071547da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/download-file1aa1e143-c5ba-4d16-8e16-48fa124c3b21-20210824170532?project=kubeflow-demos\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = api_client.create_run_from_job_spec(\n",
    "    \"dag-\"+TIMESTAMP+\".json\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    parameter_values={\"baseline_accuracy\": 80.0},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6accfb26-5127-42bc-b7f9-7528c056c13a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
